custom_scripts: "{{ vars_common_all_scripts_admin }}"

soft_packages_latest: "{{ vars_common_all_soft_apt_tools + vars_common_all_soft_apt_unattended }}"

users: "{{ vars_common_all_main_users }}"
logging_admin_pass: !vault |
  $ANSIBLE_VAULT;1.1;AES256
  36383434656461633863323939333336313534643332396364663830636366323065313233366635
  3530646562613761653664326564636166643361656462330a626665383165373233303766333034
  30643565326339383036383931386364396334356265306637623338636437656636333433626638
  3431336137656432360a363236393663376530656233663734353131633439616537333131333661
  3038

sshd: "{{ vars_common_all_default_sshd }}"

step_ca_certs_dir: "{{ vars_common_all_certs_path }}"
step_ca_certs_key: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
step_ca_certs_crt: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
step_ca_certs_jwk_pass: "{{ vars_common_all_step_ca_jwk_password }}"
step_ca_certs_pass_dir: "{{ vars_common_all_certs_path }}"
step_ca_certs:
  - name: "{{ ansible_hostname }}.{{ vars_common_all_default_domain }}"
    crt_path: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
    key_path: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
    not_after: 720h
    renew_after: 20h
    san:
      - localhost
      - 127.0.0.1
      - "{{ ansible_host }}"
#step_ca_certs_renew:
#    crt_path: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
#    key_path: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
#    renew_after: 20h

# Rsyslog server conf
rsyslog_receiver: true
rsyslog_user: root
rsyslog_group: admin
rsyslog_loki: true
#rsyslog_tls_enable: true
#rsyslog_tls_copy_keys: true
#rsyslog_tls_files_remote_src: true
#rsyslog_tls_ca_file: "{{ vars_common_all_certs_ca_path }}"
#rsyslog_tls_cert_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
#rsyslog_tls_key_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
#rsyslog_tls_certs_path: "/opt/rsyslog/tls"
#rsyslog_tls_private_path: "{{ rsyslog_tls_certs_path }}_private"

# https://github.com/prometheus-community/ansible/blob/main/roles/prometheus/defaults/main.yml
# Prometheus web settings
prometheus_web_listen_address: "0.0.0.0:9090"
prometheus_web_external_url: ""
prometheus_metrics_path: "/{{ (prometheus_web_external_url + '/metrics') | regex_replace('^(.*://)?(.*?)/') }}"
# See https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md
prometheus_web_config:
  tls_server_config:
    {}
    #cert_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
    #key_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
  http_server_config: {}
  basic_auth_users:
    monitor: $2y$10$8j6jJyH4GSYhdoRyCxU8Pe8NCVSRcQ94ZyuzWwnRVBbK7DLsNrmFW
# Prometheus alert settings
prometheus_alertmanager_config: []
# prometheus_alertmanager_config:
#   - scheme: https
#     path_prefix: alertmanager/
#     basic_auth:
#       username: user
#       password: pass
#     static_configs:
#       - targets: ["127.0.0.1:9093"]
#     proxy_url: "127.0.0.2"
prometheus_alert_relabel_configs: []
# prometheus_alert_relabel_configs:
#   - action: labeldrop
#     regex: replica
prometheus_alert_rules: # noqa yaml[line-length]  # noqa line-length
  - alert: Watchdog
    expr: vector(1)
    for: 10m
    labels:
      severity: warning
    annotations:
      description: "This is an alert meant to ensure that the entire alerting pipeline is functional.\nThis alert is always firing, therefore it should always be firing in Alertmanager\nand always fire against a receiver. There are integrations with various notification\nmechanisms that send a notification when this alert is not firing. For example the\n\"DeadMansSnitch\" integration in PagerDuty."
      summary: "Ensure entire alerting pipeline is functional"
  - alert: InstanceDown
    expr: "up == 0"
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} down{% endraw %}"
  - alert: RebootRequired
    expr: "node_reboot_required > 0"
    labels:
      severity: warning
    annotations:
      description: "{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}"
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.{% endraw %}'
      summary: "Filesystem is predicted to run out of space within the next 24 hours."
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.{% endraw %}'
      summary: "Filesystem is predicted to run out of space within the next 4 hours."
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: "Filesystem has less than 5% space left."
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: "Filesystem has less than 3% space left."
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up.{% endraw %}'
      summary: "Filesystem is predicted to run out of inodes within the next 24 hours."
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.{% endraw %}'
      summary: "Filesystem is predicted to run out of inodes within the next 4 hours."
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: "Filesystem has less than 5% inodes left."
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: "Filesystem has less than 3% inodes left."
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeNetworkReceiveErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.{% endraw %}'
      summary: "Network interface is reporting many receive errors."
    expr: "increase(node_network_receive_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeNetworkTransmitErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.{% endraw %}'
      summary: "Network interface is reporting many transmit errors."
    expr: "increase(node_network_transmit_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeHighNumberConntrackEntriesUsed
    annotations:
      description: "{% raw %}{{ $value | humanizePercentage }} of conntrack entries are used{% endraw %}"
      summary: "Number of conntrack are getting close to the limit"
    expr: "(node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75\n"
    labels:
      severity: warning
  - alert: NodeClockSkewDetected
    annotations:
      message: "{% raw %}Clock on {{ $labels.instance }} is out of sync by more than 300s. Ensure NTP is configured correctly on this host.{% endraw %}"
      summary: "Clock skew detected."
    expr: "(\n  node_timex_offset_seconds > 0.05\nand\n  deriv(node_timex_offset_seconds[5m]) >= 0\n)\nor\n(\n  node_timex_offset_seconds < -0.05\nand\n  deriv(node_timex_offset_seconds[5m]) <= 0\n)\n"
    for: 10m
    labels:
      severity: warning
  - alert: NodeClockNotSynchronising
    annotations:
      message: "{% raw %}Clock on {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.{% endraw %}"
      summary: "Clock not synchronising."
    expr: "min_over_time(node_timex_sync_status[5m]) == 0\n"
    for: 10m
    labels:
      severity: warning
# Prometheus extra settings
prometheus_global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s
prometheus_config_flags_extra: {}
# prometheus_config_flags_extra:
#   storage.tsdb.retention: 15d
#   alertmanager.timeout: 10s
# Prometheus targets
#prometheus_targets:
#  node:
#    - targets:
#        - localhost:9090
#      labels:
#        env: monitor
prometheus_scrape_configs:
  - job_name: "head"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.10:9100"
  - job_name: "logmon"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "127.0.0.1:9100"
  - job_name: "bastion"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.53:9100"
  - job_name: "proxy"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.80:9100"
  - job_name: "pve0"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.100:9100"
  - job_name: "vb0"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.120:9100"
  - job_name: "vb1"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.121:9100"
  - job_name: "vb2"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.122:9100"
  - job_name: "vs0"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.130:9100"
  - job_name: "vs1"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.131:9100"
  - job_name: "vs2"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "192.168.10.132:9100"
  - job_name: "prometheus"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "127.0.0.1:9090"
    basic_auth:
      username: "monitor"
      password: "{{ logging_admin_pass }}"
  - job_name: "consul-sd"
    consul_sd_configs:
      - server: "192.168.10.120:8501"
    relabel_configs:
      - source_labels: [__meta_consul_tags]
        regex: .*,prometheus,.*
        action: keep
      - source_labels: [__meta_consul_service]
        target_label: job
  - job_name: "nomad_metrics"
    consul_sd_configs:
      - server: "192.168.10.120:8501"
        services: ["nomad-client", "nomad"]
    relabel_configs:
      - source_labels: ["__meta_consul_tags"]
        regex: "(.*)http(.*)"
        action: keep
    metrics_path: /v1/metrics
    params:
      format: ["prometheus"]
  - job_name: "consul"
    honor_timestamps: true
    scrape_interval: 15s
    scrape_timeout: 10s
    metrics_path: "/v1/agent/metrics"
    scheme: https
    params:
      format: ["prometheus"]
    tls_config:
      cert_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
      key_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
      ca_file: "{{ vars_common_all_certs_ca_path }}"
    static_configs:
      - targets:
          - "192.168.10.120:8501"
          - "192.168.10.121:8501"
          - "192.168.10.122:8501"
          - "192.168.10.130:8501"
          - "192.168.10.131:8501"
          - "192.168.10.132:8501"
  - job_name: "nomad"
    scrape_interval: 15s
    scrape_timeout: 10s
    metrics_path: "/v1/metrics"
    scheme: https
    params:
      format: ["prometheus"]
    relabel_configs:
      - replacement: "jamlab-nomad"
        target_label: instance
    tls_config:
      cert_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.crt"
      key_file: "{{ vars_common_all_certs_path }}/{{ vars_common_all_certs_name }}.key"
      ca_file: "{{ vars_common_all_certs_ca_path }}"
    static_configs:
      - targets:
          - "192.168.10.120:4646"
          - "192.168.10.121:4646"
          - "192.168.10.122:4646"
          - "192.168.10.130:4646"
          - "192.168.10.131:4646"
          - "192.168.10.132:4646"

# Prometheus Alertmanager
alertmanager_version: latest
#alertmanager_slack_api_url: "http://example.com"
#alertmanager_receivers:
#  - name: slack
#    slack_configs:
#      - send_resolved: true
#        channel: '#alerts'
#alertmanager_route:
#  group_by: ['alertname', 'cluster', 'service']
#  group_wait: 30s
#  group_interval: 5m
#  repeat_interval: 3h
#  receiver: slack

# Grafana
grafana_security:
  admin_user: monitor
  admin_password: "{{ logging_admin_pass }}"
grafana_datasources:
  - name: loki
    type: loki
    access: proxy
    url: "http://localhost:3100"
  - name: prometheus
    type: prometheus
    access: proxy
    url: "http://localhost:9090"
    basicAuth: true
    basicAuthUser: "monitor"
    secureJsonData:
      basicAuthPassword: "{{ logging_admin_pass }}"
grafana_dashboards:
  - dashboard_id: 1860 # Node exporter
    revision_id: 33
    datasource: prometheus
  # Consul and Nomad dashboards begin
  - dashboard_id: 3662
    revision_id: 2
    datasource: prometheus
  - dashboard_id: 17549
    revision_id: 2
    datasource: prometheus
  - dashboard_id: 6278
    revision_id: 1
    datasource: prometheus
  - dashboard_id: 6281
    revision_id: 1
    datasource: prometheus
  - dashboard_id: 6281
    revision_id: 1
    datasource: prometheus
  - dashboard_id: 10642
    revision_id: 1
    datasource: prometheus
  - dashboard_id: 2351
    revision_id: 1
    datasource: prometheus
  - dashboard_id: 13396
    revision_id: 3
    datasource: prometheus
  - dashboard_id: 15859
    revision_id: 2
    datasource: prometheus
  # Consul and Nomad dashboards end

#grafana_alert_notifications:
#  notifiers:
#    - name: Channel 1
#      type: email
#      uid: channel1
#      is_default: false
#      send_reminder: false
#      settings:
#        addresses: "example@example.com"
#        autoResolve: true
#  delete_notifiers:
#    - name: Channel 2
#      uid: channel2

loki_version: 2.9.1
loki_install: true
loki_config_http_address: 0.0.0.0
